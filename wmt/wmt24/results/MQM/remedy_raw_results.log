lang:                                                    en-de     en-de     en-es     en-es     ja-zh     ja-zh
level:                                                     Sys       Seg       Sys       Seg       Sys       Seg
corr_fcn:                                                  SPA    acc_eq       SPA    acc_eq       SPA    acc_eq
metric                                      Avg Corr     task1     task2     task3     task4     task5     task6
------------------------------------------  --------  --------  --------  --------  --------  --------  --------
REMEDY-9b                                    1 0.728   9 0.857   2 0.539   8 0.788   8 0.684   1 0.928   1 0.572
metametrics_mt_mqm_hybrid_kendall            2 0.724   3 0.882   1 0.542   2 0.803   4 0.686   9 0.871   2 0.561
MetricX-24-Hybrid                            3 0.721   7 0.873   3 0.532   4 0.798   6 0.685   4 0.896   4 0.539
XCOMET                                       4 0.719   1 0.906   4 0.530   7 0.789   2 0.688   5 0.889   7 0.510
MetricX-24-Hybrid-QE[noref]                  5 0.714   6 0.879   5 0.526   6 0.792   7 0.685   7 0.875   5 0.530
gemba_esa[noref]                             6 0.711  13 0.791   8 0.507   1 0.840  12 0.683   3 0.908   3 0.539
XCOMET-QE[noref]                             7 0.695   2 0.891   6 0.520   3 0.801   3 0.687  16 0.807  15 0.463
COMET-22                                     8 0.689   5 0.879  12 0.482  10 0.779  13 0.683  15 0.814   8 0.496
BLEURT-20                                    9 0.686   4 0.881  11 0.486  12 0.696  18 0.681   6 0.887  12 0.484
metametrics_mt_mqm_qe_kendall.seg.s[noref]  10 0.684   8 0.858  10 0.497  11 0.710   5 0.686  13 0.838   6 0.516
bright-qe[noref]                            11 0.681  12 0.817   9 0.500   5 0.794   1 0.689  17 0.805  11 0.484
BLCOM_1                                     12 0.665  10 0.843  14 0.455  14 0.682  17 0.681  12 0.842  10 0.488
sentinel-cand-mqm[noref]                    13 0.650  11 0.821   7 0.517   9 0.787  11 0.683  24 0.610  13 0.481
PrismRefMedium                              14 0.646  14 0.776  20 0.434  15 0.650  21 0.680  10 0.871  16 0.462
PrismRefSmall                               15 0.642  15 0.772  22 0.433  16 0.632  23 0.680   8 0.875  18 0.457
CometKiwi[noref]                            16 0.640  23 0.732  13 0.467  13 0.693   9 0.684  20 0.775   9 0.490
damonmonli                                  17 0.636  24 0.699  16 0.443  18 0.607  15 0.682   2 0.912  14 0.472
YiSi-1                                      18 0.630  16 0.762  18 0.436  17 0.609  19 0.681  14 0.835  17 0.458
BERTScore                                   19 0.618  18 0.753  19 0.435  19 0.589  14 0.682  18 0.800  19 0.451
MEE4                                        20 0.609  22 0.732  17 0.437  26 0.500  10 0.683  11 0.857  20 0.446
chrF                                        21 0.608  17 0.753  23 0.431  20 0.582  25 0.680  21 0.766  24 0.436
chrfS                                       22 0.607  19 0.746  21 0.434  21 0.549  16 0.682  19 0.788  21 0.444
spBLEU                                      23 0.594  20 0.743  25 0.431  22 0.525  22 0.680  22 0.746  23 0.436
BLEU                                        24 0.589  21 0.737  24 0.431  25 0.514  24 0.680  23 0.736  27 0.435
sentinel-src-mqm[noref]                     25 0.517  27 0.571  27 0.429  23 0.525  27 0.680  26 0.459  26 0.435
sentinel-ref-mqm                            26 0.516  26 0.572  26 0.429  24 0.524  26 0.680  27 0.457  25 0.435
XLsimMqm[noref]                             27 0.516  25 0.614  15 0.450  27 0.363  20 0.681  25 0.550  22 0.438

